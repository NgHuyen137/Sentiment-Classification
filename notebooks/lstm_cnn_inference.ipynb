{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25910d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d11d5518",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextClassifier(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_classes,\n",
    "        vocab_size,\n",
    "        embedding_dim,\n",
    "        embedding_tensors,\n",
    "        lstm_hidden_size,\n",
    "        conv_in_channels,\n",
    "        conv_out_channels,\n",
    "        fc_in_features,\n",
    "        fc_out_features\n",
    "    ):\n",
    "        super(TextClassifier, self).__init__()\n",
    "\n",
    "        # Embedding layer\n",
    "        if embedding_tensors is not None:\n",
    "          self.embedding = nn.Embedding.from_pretrained(embedding_tensors, freeze=False).to(device)\n",
    "        else:\n",
    "          self.embedding = nn.Embedding(num_embeddings=vocab_size, embedding_dim=embedding_dim)\n",
    "\n",
    "        # Dropout\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "\n",
    "        # LSTM\n",
    "        self.LSTM = nn.LSTM(input_size=embedding_dim, hidden_size=lstm_hidden_size, batch_first=True)\n",
    "\n",
    "        # CNN\n",
    "        self.Conv1 = nn.Conv1d(in_channels=conv_in_channels, out_channels=conv_out_channels, kernel_size=3)\n",
    "        self.Conv2 = nn.Conv1d(in_channels=conv_in_channels, out_channels=conv_out_channels, kernel_size=5)\n",
    "        self.Conv3 = nn.Conv1d(in_channels=conv_in_channels, out_channels=conv_out_channels, kernel_size=7)\n",
    "\n",
    "        # Fully connected layer\n",
    "        self.fc = nn.Linear(in_features=fc_in_features, out_features=fc_out_features)\n",
    "\n",
    "        # Output layer\n",
    "        self.output = nn.Linear(in_features=fc_out_features, out_features=num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embeds = self.embedding(x) # (batch_size, sequence_length, embedding_dim)\n",
    "        lstm_out, _ = self.LSTM(embeds) # (batch_size, sequence_length, 128)\n",
    "        lstm_out = lstm_out[:, -1, :] # Select the last time step in each batch\n",
    "\n",
    "        embeds = embeds.permute(0, 2, 1) # (batch_size, embedding_dim, sequence_length)\n",
    "        conv1_out = F.relu(self.Conv1(embeds))\n",
    "        conv1_out = torch.max(conv1_out, dim=2)[0] # (batch_size, conv_out_channels)\n",
    "\n",
    "        conv2_out = F.relu(self.Conv2(embeds))\n",
    "        conv2_out = torch.max(conv2_out, dim=2)[0]\n",
    "\n",
    "        conv3_out = F.relu(self.Conv3(embeds))\n",
    "        conv3_out = torch.max(conv3_out, dim=2)[0]\n",
    "\n",
    "        conv_concat = torch.cat((conv1_out, conv2_out, conv3_out), dim=1) # (batch_size, 3 * conv_out_channels)\n",
    "\n",
    "        lstm_cnn_concat = torch.cat((lstm_out, conv_concat), dim=1) # (batch_size, 3 * conv_out_channels + 128)\n",
    "        fc_out = self.dropout(F.relu(self.fc(lstm_cnn_concat)))\n",
    "        output = self.output(fc_out)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "336cc499",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_sentence(sentence: str, word_to_index: dict, max_tokens: int) -> list:\n",
    "    fixed_encoded = np.zeros(max_tokens, dtype=int)\n",
    "    encoded = np.array([word_to_index.get(word, len(word_to_index)) for word in sentence.split(\" \")])\n",
    "\n",
    "    # Ensure the encoded sentence reaches the maximum specified length.\n",
    "    length = min(max_tokens, len(encoded))\n",
    "    fixed_encoded[:length] = encoded[:length]\n",
    "    return list(fixed_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1951502c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_cnn_model = torch.load(\"../models/lstm_cnn_model.pth\", map_location=\"cpu\", weights_only=False)[\"model\"]\n",
    "\n",
    "with open(\"../models/word_to_index.json\", \"r\") as f:\n",
    "    word_to_index = json.load(f)\n",
    "    word_to_index = {k: int(v) for k, v in word_to_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21e4e493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence:  Thầy dạy nhanh, khó tiếp thu.\n",
      "True Label:  Negative\n",
      "Predicted Label:  Negative\n"
     ]
    }
   ],
   "source": [
    "label_map = {\n",
    "    0: \"Negative\",\n",
    "    1: \"Neutral\",\n",
    "    2: \"Positive\"\n",
    "}\n",
    "\n",
    "sentence = \"Thầy dạy nhanh, khó tiếp thu.\"\n",
    "true_label = 0\n",
    "\n",
    "encodings = torch.tensor(encode_sentence(sentence, word_to_index, max_tokens=200)).unsqueeze(0)\n",
    "logits = lstm_cnn_model(encodings)\n",
    "predicted_label = torch.argmax(torch.softmax(logits, dim=1), dim=1).item()\n",
    "\n",
    "print(\"Sentence: \", sentence)\n",
    "print(\"True Label: \", label_map[true_label])\n",
    "print(\"Predicted Label: \", label_map[predicted_label])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
